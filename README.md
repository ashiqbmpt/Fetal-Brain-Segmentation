# Fetal Brain MRI Segmentation Benchmark Framework

This repository provides a PyTorch-based benchmarking framework for fetal brain tissue segmentation from MRI scans.

The framework includes:

- Proposed model (ResNet-34 + Lightweight Decoder)
- Multiple baseline segmentation models
- Cross-validation training
- Standardized evaluation metrics
- Modular and extensible design

This repository is designed for research reproducibility and model comparison.

---

## ğŸ”¬ Implemented Models

### âœ… Proposed Model
- ResNet-34 encoder
- Custom lightweight decoder

### ğŸ“Š Baseline Models Included

The following segmentation models are supported:

- UNet
- UNet++
- DeepLabV3
- DeepLabV3+
- FPN
- PSPNet
- SegFormer
-----
- Custom ONN-based decoders (if enabled)

All models can be selected via configuration.

---

## ğŸ“ Project Structure
Fetal-Brain-Segmentation/
â”‚
â”œâ”€â”€ configs/
â”‚ â”œâ”€â”€ config.py
â”‚ â””â”€â”€ config_test.py
â”‚
â”œâ”€â”€ preprocessing/
â”‚ â””â”€â”€ CreateFolds.m
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ data/
â”‚ â”‚ â””â”€â”€ dataset.py
â”‚ â”‚
â”‚ â”œâ”€â”€ models/
â”‚ â”‚ â””â”€â”€ models.py
â”‚ â”‚
â”‚ â””â”€â”€ utils/
â”‚ â”œâ”€â”€ utils.py
â”‚ â””â”€â”€ image_mean_std.py
â”‚
â”œâ”€â”€ training/
â”‚ â”œâ”€â”€ train.py
â”‚ â””â”€â”€ test.py
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

---

## ğŸ“‚ Dataset Format

Expected dataset structure:
Data/
â”œâ”€â”€ Train/
â”‚ â”œâ”€â”€ fold_1/
â”‚ â”‚ â”œâ”€â”€ images/
â”‚ â”‚ â””â”€â”€ masks/
â”‚
â”œâ”€â”€ Val/
â”‚ â”œâ”€â”€ fold_1/
â”‚ â”‚ â”œâ”€â”€ images/
â”‚ â”‚ â””â”€â”€ masks/
â”‚
â””â”€â”€ Test/
â”œâ”€â”€ fold_1/
â”œâ”€â”€ images/
â””â”€â”€ masks/

---

## âš™ï¸ Configuration

All experiments are controlled via:

You can modify:

- Model type
- Encoder backbone
- Loss function
- Learning rate
- Batch size
- Number of folds
- Decoder type
- Attention mechanism

---

## ğŸš€ Training

Run from the project root:

You can modify:

- Model type
- Encoder backbone
- Loss function
- Learning rate
- Batch size
- Number of folds
- Decoder type
- Attention mechanism

---

## ğŸš€ Training

Run from the project root:
training/train.py


---

## ğŸ§ª Evaluation
training/test.py


---

## ğŸ“Š Evaluation Metrics

The framework computes:

- Accuracy
- Intersection over Union (IoU)
- Dice Score (DSC)
- Per-class metrics (for multi-class segmentation)

---

## ğŸ”„ Cross-Validation

- Patient-wise fold separation
- Multi-fold training supported
- Average performance reporting

---

## ğŸ–¥ï¸ Hardware Support

- CUDA GPU recommended
- Multi-GPU supported
- CPU fallback available

---

## ğŸ§  Extensibility

Researchers can easily:

- Add new encoders
- Add new decoders
- Implement new loss functions
- Plug in transformer-based models
- Add 3D models

The architecture is modular to support future research extensions.

---

## ğŸ“œ License

MIT License

---

## ğŸ‘¨â€ğŸ”¬ Intended Use

This repository is intended for:

- Academic research
- Model benchmarking
- Reproducible experiments
- Fetal MRI segmentation studies

